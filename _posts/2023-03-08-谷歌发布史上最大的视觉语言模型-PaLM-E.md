---
title: 谷歌发布史上最大的视觉语言模型 PaLM-E
date: 2023-03-08 20:25:42
cover: https://pic.imgdb.cn/item/64087f36f144a01007c629ce.jpg
categories: google
tags:
 - google
 - PaLM-E
 - AI
---

谷歌 PaLM-E 有着5620亿参数 (ChatGPT 为1750亿参数) ，结合了 PaLM-540B 语言模型与 ViT-22B 视觉模型。将现实世界的连续传感器模态直接纳入语言模型，"为AI移植眼睛"从而建立单词和感知之间的联系。
![](https://pic.imgdb.cn/item/64087f36f144a01007c62989.jpg)
PaLM-E 直接从机器人摄像头获取原始图像数据，并根据自然语言指令进行动作规划和执行，这样就避免了人工预处理或标注数据的需要，可以端到端自主学习这些任务。
![](https://pic.imgdb.cn/item/64087f36f144a01007c629ce.jpg)
研究团队同时发现：
1. 语言模型越大，在视觉语言和机器人任务训练时就越能保持其语言能力，PaLM-E 的5620亿的参数量刚好让它保留住了几乎所有语言能力。
2. "通才AI"的正迁移能力，同时在多个任务领域训练的 PaLM-E，单任务能力相比"专精AI"显着提高。
3. 除了人机交互方面有着重大进展，团队还发现了 PaLM-E 有着诸如多模态思维链推理和多图像推理等新兴能力，在 OK-VQA 视觉问答基准测试上达成了新的 SOTA (最佳水平AI)。